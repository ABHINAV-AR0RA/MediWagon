import * as environments from "../../../../environments";
import * as core from "../../../../core";
import * as ElevenLabs from "../../../index";
export declare namespace TextToDialogue {
    interface Options {
        environment?: core.Supplier<environments.ElevenLabsEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        /** Override the xi-api-key header */
        apiKey?: core.Supplier<string | undefined>;
        /** Additional headers to include in requests. */
        headers?: Record<string, string | core.Supplier<string | null | undefined> | null | undefined>;
    }
    interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Override the xi-api-key header */
        apiKey?: string | undefined;
        /** Additional query string parameters to include in the request. */
        queryParams?: Record<string, unknown>;
        /** Additional headers to include in the request. */
        headers?: Record<string, string | core.Supplier<string | null | undefined> | null | undefined>;
    }
}
export declare class TextToDialogue {
    protected readonly _options: TextToDialogue.Options;
    constructor(_options?: TextToDialogue.Options);
    /**
     * Converts a list of text and voice ID pairs into speech (dialogue) and returns audio.
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     */
    convert(request: ElevenLabs.BodyTextToDialogueMultiVoiceV1TextToDialoguePost, requestOptions?: TextToDialogue.RequestOptions): core.HttpResponsePromise<ReadableStream<Uint8Array>>;
    private __convert;
    /**
     * Converts a list of text and voice ID pairs into speech (dialogue) and returns an audio stream.
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     */
    stream(request: ElevenLabs.BodyTextToDialogueMultiVoiceStreamingV1TextToDialogueStreamPost, requestOptions?: TextToDialogue.RequestOptions): core.HttpResponsePromise<ReadableStream<Uint8Array>>;
    private __stream;
    /**
     * Converts a list of text and voice ID pairs into speech (dialogue) and returns a stream of JSON blobs containing audio as a base64 encoded string and timestamps
     */
    streamWithTimestamps(request: ElevenLabs.BodyTextToDialogueStreamWithTimestamps, requestOptions?: TextToDialogue.RequestOptions): core.HttpResponsePromise<core.Stream<ElevenLabs.StreamingAudioChunkWithTimestampsAndVoiceSegmentsResponseModel>>;
    private __streamWithTimestamps;
    /**
     * Generate dialogue from text with precise character-level timing information for audio-text synchronization.
     *
     * @param {ElevenLabs.BodyTextToDialogueFullWithTimestamps} request
     * @param {TextToDialogue.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.textToDialogue.convertWithTimestamps({
     *         outputFormat: "mp3_22050_32",
     *         inputs: [{
     *                 text: "Hello, how are you?",
     *                 voiceId: "bYTqZQo3Jz7LQtmGTgwi"
     *             }, {
     *                 text: "I'm doing well, thank you!",
     *                 voiceId: "6lCwbsX1yVjD49QmpkTR"
     *             }]
     *     })
     */
    convertWithTimestamps(request: ElevenLabs.BodyTextToDialogueFullWithTimestamps, requestOptions?: TextToDialogue.RequestOptions): core.HttpResponsePromise<ElevenLabs.AudioWithTimestampsAndVoiceSegmentsResponseModel>;
    private __convertWithTimestamps;
}
